<!doctype html>
<html>
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="initial-scale=1,minimum-scale=1,maximum-scale=1" />
    <title>KMT Mixer</title>
</head>
<body>
    <p><a href="#" class="play">play</a></p>
    <p><a href="#" class="stop">stop</a></p>
    <div id="mixer1"></div>
    <script src="js/Mixer.js"></script>
    <script>
            var context, 
        soundSource, 
        soundSource2, 
        soundBuffer,
        url1 = 'audio/instrumental.mp3',
        url2 = 'audio/acapella.mp3';
        window.sounds = [];

    // Step 1 - Initialise the Audio Context
    // There can be only one!
    function init() {
        if (typeof AudioContext !== "undefined") {
            context = new AudioContext();
        } else if (typeof webkitAudioContext !== "undefined") {
            context = new webkitAudioContext();
        } else {
            throw new Error('AudioContext not supported. :(');
        }
        
        loadSound(url1, soundSource);
        loadSound(url2, soundSource2);
    }

    // Step 2: Load our Sound using XHR
    function loadSound(url, soundSrc) {
        console.log('loadSound', url, soundSrc);
        // Note: this loads asynchronously
        request = new XMLHttpRequest();
        request.open('GET', url, true);
        request.responseType = 'arraybuffer';
        request.addEventListener('load', function(e) {
            var source = context.createBufferSource();
            source.buffer = context.createBuffer(e.target.response, false);
            source.connect(context.destination);
            window.sounds.push(source);
            //audioGraph(e.target, soundSrc);
        }, false);
        request.send();
    }

    // Finally: tell the source when to start
    function playSound(soundSrc) {
        // play the source now
        console.log(soundSrc, context.currentTime);
        soundSrc.noteOn(0);
    }

    function stopSound(soundSrc) {
        // stop the source now
        console.log(soundSrc, context.currentTime);
        soundSrc.noteOff(0);
    }

    // Events for the play/stop bottons
    document.querySelector('.play').addEventListener('click', function() {
        playSound(window.sounds[0]);
        playSound(window.sounds[1]);
    });
    document.querySelector('.stop').addEventListener('click', function() {
        stopSound(window.sounds[0]);
        stopSound(window.sounds[1]);
    });


    // This is the code we are interested in
    function audioGraph(audioData, soundSrc) {
        
        // create a sound source
        var soundSrc = context.createBufferSource();

        // The Audio Context handles creating source buffers from raw binary
        soundBuffer = context.createBuffer(audioData, true/* make mono */);
      
        // Add the buffered data to our object
        soundSrc.buffer = soundBuffer;
        soundSrc.loop = true;

        // Plug the cable from one thing to the other
        soundSrc.connect(context.destination);

        // Finally
        console.log('audioGraph', audioData, soundSrc);
        
        window.sounds.push(soundSrc);
        //playSound(soundSrc);
    }


    init();

        //var mixer = new Mixer('mixer1', { instrumental: 'audio/instrumental.mp3', acapella: 'audio/acapella.mp3' });
    </script>
</body>
</html>